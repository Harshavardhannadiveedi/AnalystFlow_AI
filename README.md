# ğŸ“Š AnalystFlow-AI

**AnalystFlow-AI** is an end-to-end **automated data analysis and preprocessing web application** built using **Streamlit**.
It helps users **understand, clean, preprocess, visualize, validate, and export datasets**â€”all through an intuitive UIâ€”without writing code.

This tool is especially useful for:

* Data Science students
* ML beginners
* Analysts preparing datasets for machine learning
* Hackathons & academic projects

---

## ğŸš€ Features Overview

### ğŸ”¹ Step 1: Dataset Upload & Understanding

* Upload **CSV or Excel** files
* Automatic dataset profiling:

  * Preview
  * Shape (rows & columns)
  * Data types
  * Missing values
  * Duplicate rows
  * Statistical summary

---

### ğŸ”¹ Step 2: Missing Value Handling

Choose the **best practice** strategy:

* âœ… Replace missing values

  * **Numerical â†’ Median**
  * **Categorical â†’ Mode**
* âŒ Drop rows with missing values
* Undo support for safe experimentation

---

### ğŸ”¹ Step 3: Advanced Data Cleaning

* **Duplicate row removal**
* **Outlier treatment using IQR method**

  * Applied individually to all numerical columns
  * Caps outliers instead of deleting rows

---

### ğŸ”¹ Step 4: Data Preprocessing

#### ğŸ“ Feature Scaling

* Standardization (Z-score)
* Normalization (Min-Max)

#### ğŸ”¤ Categorical Encoding

* Label Encoding
* One-Hot Encoding

---

### ğŸ”¹ Step 5: Visual Validation (Before vs After)

Visual comparison using:

* ğŸ“¦ Boxplots
* ğŸ“ Scatter plots
* ğŸ”¥ Correlation heatmaps
* ğŸ”— Feature vs Target correlation analysis

> Raw data is kept **immutable**, ensuring unbiased comparison.

---

### ğŸ”¹ Step 6: Export & Data Readiness Report

* Export cleaned dataset as:

  * CSV
  * Excel
* Rule-based **data readiness summary**
* Complete operation history log

---

## ğŸ¤– AI-Generated Data Readiness Explanation (Optional)

AnalystFlow-AI follows a **deterministic-first, AI-second architecture**.

### ğŸ”˜ When AI is ENABLED

* Groq LLM generates a **professional data readiness report**
* Uses:

  * Raw dataset statistics
  * Cleaned dataset statistics
  * Actual preprocessing steps performed
* Output explains:

  1. How data quality improved
  2. Why each preprocessing step is best practice
  3. Why the dataset is ML-ready

### ğŸ”˜ When AI is DISABLED

* No API calls are made
* Rule-based validation alone confirms dataset readiness

### ğŸ§  Why This Design Matters

* Prevents unnecessary API costs
* Avoids AI dependency for correctness
* Ensures reproducibility & reliability
* Graceful fallback if AI is unavailable

> AI is used **only for explanation**, not decision-making.

## ğŸ§  Why AnalystFlow-AI?

âœ” Prevents data leakage
âœ” Enforces ML best practices
âœ” Beginner-friendly yet professional
âœ” Undo support for safe exploration
âœ” Visualization-driven validation
âœ” Optional AI explanation

---

## ğŸ› ï¸ Tech Stack

| Component        | Technology          |
| ---------------- | ------------------- |
| Frontend         | Streamlit           |
| Backend Logic    | Python              |
| Data Handling    | Pandas, NumPy       |
| Visualization    | Matplotlib, Seaborn |
| ML Preprocessing | Scikit-learn        |
| AI Integration   | Groq LLM (Optional) |
| Environment      | Python-dotenv       |

---

## ğŸ“ Project Structure

```
AnalystFlow-AI/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (Groq API key)
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ sample_datasets/       # (Optional) Example datasets
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/AnalystFlow-AI.git
cd AnalystFlow-AI
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate     # macOS/Linux
venv\Scripts\activate        # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Optional: Enable AI Explanation (Groq)

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key_here
```

> âš ï¸ If not provided, the app still works perfectly using rule-based validation.

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

Then open:

```
http://localhost:8501
```

---

## ğŸ“Š Example Use Cases

* ML dataset preprocessing before training
* Academic mini & major projects
* Hackathons
* Resume projects
* Teaching data cleaning concepts visually

---

## ğŸ§ª ML Best Practices Followed

* Immutable raw dataset
* Separate working dataset
* Median & Mode for imputation
* IQR-based outlier handling
* Scaling before distance-based models
* Visual validation before export

---

## ğŸ§© Future Enhancements

* Feature selection
* Train-test split
* Model training & evaluation
* Automated EDA reports
* Dataset versioning
* SHAP-based explainability

---

## ğŸ‘¨â€ğŸ’» Author

**Harshavardhan Nadiveedi**
B.Tech AIML Student
Focused on **Data Science, ML & AI Projects**

---

## â­ If you like this project

Give it a â­ on GitHub and feel free to fork & extend it!



